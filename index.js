const wa = require('@open-wa/wa-automate');
const mime = require('mime-types');
const fs = require('fs');
const { Configuration, OpenAIApi } = require("openai");

require('dotenv').config();
const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(configuration);
const path_mp3 = process.env.PATH_MP3 ? process.env.PATH_MP3 : '.' ;
const sessionDataPath = process.env.PATH_SESSION ? process.env.PATH_SESSION : './' ;
const groups = process.env.GROUPS ? process.env.GROUPS : 'xxxx,yyyy' ;
const allowedGroups = groups.split(',');
const user_phone = process.env.USER_PHONE ? process.env.USER_PHONE +'@c.us' : 'NA' ;

wa.create({
    useChrome: true,
    sessionId: "WhatsAppTranscription",
    multiDevice: true, //required to enable multiDevice support
    authTimeout: 60, //wait only 60 seconds to get a connection with the host account device
    blockCrashLogs: true,
    disableSpins: true,
    headless: true,
    hostNotificationLang: 'PT_BR',
    logConsole: true,
    popup: true,
    qrTimeout: 0, //0 means it will wait forever for you to scan the qr code
    sessionDataPath,
}).then(client => start(client));

function start(client) {
    client.onAnyMessage(async message => {
        console.log(message);

        // Save voice messages
        if (message.type === "ptt" || message.type === "audio") {
            const filename = `${path_mp3}/${message.id}.${mime.extension(message.mimetype)}`;
            const mediaData = await wa.decryptMedia(message);

            fs.writeFile(filename, mediaData, err => {
                if (err) { return console.log(err); }
                console.log('Voice file saved:', filename);
            });
        }

        // Check for "!ler" reply and transcribe
        if ((`${user_phone}` === "NA" || message.from === `${user_phone}`) && message.body === "!ler" && message.quotedMsg && (message.quotedMsg.type === "ptt" || message.quotedMsg === "audio")) {
            const originalMessageId = message.quotedMsg.id;
            const filePath = `${path_mp3}/${originalMessageId}.${mime.extension(message.quotedMsg.mimetype)}`;

            if (fs.existsSync(filePath)) {
                const resp = await openai.createTranscription(fs.createReadStream(filePath), "whisper-1");
                console.log(`Transcribed text: ${resp.data.text}`);
                await client.reply(message.chatId, `üó£Ô∏è ${resp.data.text}`, message.id);
            } else {
                console.log('File not found for transcription:', filePath);
            }
        }
    });
}
